{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddunn.CUREXCURRENCY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import plotly_express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn import metrics\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for transforming new datasets\n",
    "metrics = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\Denis_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed test set\n",
    "test_df = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\transformed_new_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = pd.read_csv(r\"C:\\Users\\ddunn.CUREXCURRENCY\\Desktop\\denis_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = pd.read_csv(r'S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\November_2020\\activation_tob_volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1089700 entries, 0 to 1089699\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                  Non-Null Count    Dtype  \n",
      "---  ------                                  --------------    -----  \n",
      " 0   Unnamed: 0                              1089700 non-null  int64  \n",
      " 1   MissFill                                1089700 non-null  object \n",
      " 2   AggressivePassive                       1089700 non-null  object \n",
      " 3   Symbol                                  1089700 non-null  object \n",
      " 4   OrderId                                 1089700 non-null  int64  \n",
      " 5   BuySell                                 1089700 non-null  object \n",
      " 6   time_difference                         1089700 non-null  float64\n",
      " 7   z_USDEquivalentAmount                   1089694 non-null  float64\n",
      " 8   z_Denis_activation_spread               1089694 non-null  float64\n",
      " 9   z_PlacementSpread                       1089694 non-null  float64\n",
      " 10  price_vs_placement_bid                  1089700 non-null  float64\n",
      " 11  price_vs_placement_ask                  1089700 non-null  float64\n",
      " 12  price_vs_activation_bid                 1089700 non-null  float64\n",
      " 13  price_vs_activation_ask                 1089700 non-null  float64\n",
      " 14  pre_placement_vs_received_time_diff     1089700 non-null  float64\n",
      " 15  price_vs_pre_placement_book_join_price  1089700 non-null  float64\n",
      "dtypes: float64(10), int64(2), object(4)\n",
      "memory usage: 133.0+ MB\n"
     ]
    }
   ],
   "source": [
    "idd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(join,idd,left_on='ORDERID',right_on='OrderId',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set_tob.to_csv('tob_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\November_2020\\fils_and_misses_nov_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 135743 entries, 0 to 135742\n",
      "Data columns (total 54 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   ORDERID                            135743 non-null  int64  \n",
      " 1   TOB.BID_AMOUNT                     135743 non-null  float64\n",
      " 2   TOB.ASK_AMOUNT                     135743 non-null  float64\n",
      " 3   FirmName                           135743 non-null  object \n",
      " 4   ClientFirmName                     135743 non-null  object \n",
      " 5   ClientIdentified                   135743 non-null  object \n",
      " 6   UserName                           135743 non-null  object \n",
      " 7   ReceiveTime                        135743 non-null  object \n",
      " 8   ActivationTime                     135743 non-null  object \n",
      " 9   ReceiveTimeEST                     135743 non-null  object \n",
      " 10  ActivationTimeEST                  135743 non-null  object \n",
      " 11  Year                               135743 non-null  int64  \n",
      " 12  YearQuarter                        135743 non-null  int64  \n",
      " 13  WeekOfYear                         135743 non-null  int64  \n",
      " 14  TradingWeek                        135743 non-null  object \n",
      " 15  TradeDate                          135743 non-null  object \n",
      " 16  MissClass                          135659 non-null  object \n",
      " 17  MissDelta                          135743 non-null  int64  \n",
      " 18  AggressivePassive                  135743 non-null  object \n",
      " 19  OrderId                            135743 non-null  int64  \n",
      " 20  Symbol                             135743 non-null  object \n",
      " 21  OrderType                          135743 non-null  object \n",
      " 22  TIF                                135743 non-null  object \n",
      " 23  BuySell                            135743 non-null  object \n",
      " 24  MissFill                           135743 non-null  object \n",
      " 25  MissFillPartial                    135743 non-null  object \n",
      " 26  OrderPrice                         135743 non-null  float64\n",
      " 27  OrderAmount                        135743 non-null  float64\n",
      " 28  OrderAmountDone                    135743 non-null  float64\n",
      " 29  PlacementBid                       135743 non-null  float64\n",
      " 30  PlacementAsk                       135743 non-null  float64\n",
      " 31  ActivationBid                      135743 non-null  float64\n",
      " 32  ActivationAsk                      135743 non-null  float64\n",
      " 33  MATCH_EXISTED_PRIOR_TO_PLACEMENT   135743 non-null  object \n",
      " 34  MATCH_EXISTED_AT_PLACEMENT_TIME    135743 non-null  object \n",
      " 35  MATCH_EXISTED_DURING_RANDOM_DELAY  135743 non-null  object \n",
      " 36  PriceExpirationTime                135743 non-null  object \n",
      " 37  MissReason                         135743 non-null  object \n",
      " 38  USDEquivalentAmount                135743 non-null  float64\n",
      " 39  USDConverationPrice                135743 non-null  float64\n",
      " 40  OrderPlacementPosition             135743 non-null  object \n",
      " 41  OrderActivationPosition            135743 non-null  object \n",
      " 42  MissPriceDeltaPips                 135743 non-null  float64\n",
      " 43  PlacementSpread                    135701 non-null  float64\n",
      " 44  EndToEndLifetimeMs                 135743 non-null  int64  \n",
      " 45  WorkingLifetimeMs                  135743 non-null  int64  \n",
      " 46  WorkingLifetimeBucket              135743 non-null  object \n",
      " 47  TimeToActivationMics               135743 non-null  int64  \n",
      " 48  FutureMatch                        135743 non-null  object \n",
      " 49  FutureMatchMs                      135743 non-null  int64  \n",
      " 50  FutureMatchBucket                  135743 non-null  object \n",
      " 51  PRE_PLACEMENT_BOOK_JOIN_STATUS     135743 non-null  object \n",
      " 52  PRE_PLACEMENT_BOOK_JOIN_PRICE      135743 non-null  float64\n",
      " 53  PRE_PLACEMENT_BOOK_JOIN_TIME       135743 non-null  object \n",
      "dtypes: float64(14), int64(10), object(30)\n",
      "memory usage: 57.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_set_tob.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145199 entries, 0 to 145198\n",
      "Data columns (total 51 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   FirmName                           145199 non-null  object \n",
      " 1   ClientFirmName                     145199 non-null  object \n",
      " 2   ClientIdentified                   145199 non-null  object \n",
      " 3   UserName                           145199 non-null  object \n",
      " 4   ReceiveTime                        145199 non-null  object \n",
      " 5   ActivationTime                     145199 non-null  object \n",
      " 6   ReceiveTimeEST                     145199 non-null  object \n",
      " 7   ActivationTimeEST                  145199 non-null  object \n",
      " 8   Year                               145199 non-null  int64  \n",
      " 9   YearQuarter                        145199 non-null  int64  \n",
      " 10  WeekOfYear                         145199 non-null  int64  \n",
      " 11  TradingWeek                        145199 non-null  object \n",
      " 12  TradeDate                          145199 non-null  object \n",
      " 13  MissClass                          145107 non-null  object \n",
      " 14  MissDelta                          145199 non-null  int64  \n",
      " 15  AggressivePassive                  145199 non-null  object \n",
      " 16  OrderId                            145199 non-null  int64  \n",
      " 17  Symbol                             145199 non-null  object \n",
      " 18  OrderType                          145199 non-null  object \n",
      " 19  TIF                                145199 non-null  object \n",
      " 20  BuySell                            145199 non-null  object \n",
      " 21  MissFill                           145199 non-null  object \n",
      " 22  MissFillPartial                    145199 non-null  object \n",
      " 23  OrderPrice                         145199 non-null  float64\n",
      " 24  OrderAmount                        145199 non-null  float64\n",
      " 25  OrderAmountDone                    145199 non-null  float64\n",
      " 26  PlacementBid                       145199 non-null  float64\n",
      " 27  PlacementAsk                       145199 non-null  float64\n",
      " 28  ActivationBid                      145199 non-null  float64\n",
      " 29  ActivationAsk                      145199 non-null  float64\n",
      " 30  MATCH_EXISTED_PRIOR_TO_PLACEMENT   145199 non-null  object \n",
      " 31  MATCH_EXISTED_AT_PLACEMENT_TIME    145199 non-null  object \n",
      " 32  MATCH_EXISTED_DURING_RANDOM_DELAY  145199 non-null  object \n",
      " 33  PriceExpirationTime                145199 non-null  object \n",
      " 34  MissReason                         145199 non-null  object \n",
      " 35  USDEquivalentAmount                145199 non-null  float64\n",
      " 36  USDConverationPrice                145199 non-null  float64\n",
      " 37  OrderPlacementPosition             145199 non-null  object \n",
      " 38  OrderActivationPosition            145199 non-null  object \n",
      " 39  MissPriceDeltaPips                 145199 non-null  float64\n",
      " 40  PlacementSpread                    145140 non-null  float64\n",
      " 41  EndToEndLifetimeMs                 145199 non-null  int64  \n",
      " 42  WorkingLifetimeMs                  145199 non-null  int64  \n",
      " 43  WorkingLifetimeBucket              145199 non-null  object \n",
      " 44  TimeToActivationMics               145199 non-null  int64  \n",
      " 45  FutureMatch                        145199 non-null  object \n",
      " 46  FutureMatchMs                      145199 non-null  int64  \n",
      " 47  FutureMatchBucket                  145199 non-null  object \n",
      " 48  PRE_PLACEMENT_BOOK_JOIN_STATUS     145199 non-null  object \n",
      " 49  PRE_PLACEMENT_BOOK_JOIN_PRICE      145199 non-null  float64\n",
      " 50  PRE_PLACEMENT_BOOK_JOIN_TIME       145199 non-null  object \n",
      "dtypes: float64(12), int64(9), object(30)\n",
      "memory usage: 56.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_tob = pd.merge(join,test_df,left_on='ORDERID',right_on='OrderId',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33425 entries, 0 to 33424\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ORDERID                                 33425 non-null  int64  \n",
      " 1   TOB.BID_AMOUNT                          33425 non-null  float64\n",
      " 2   TOB.ASK_AMOUNT                          33425 non-null  float64\n",
      " 3   Unnamed: 0                              33425 non-null  int64  \n",
      " 4   MissFill                                33425 non-null  object \n",
      " 5   AggressivePassive                       33425 non-null  object \n",
      " 6   Symbol                                  33425 non-null  object \n",
      " 7   OrderId                                 33425 non-null  int64  \n",
      " 8   BuySell                                 33425 non-null  object \n",
      " 9   time_difference                         33425 non-null  float64\n",
      " 10  z_USDEquivalentAmount                   33425 non-null  float64\n",
      " 11  z_Denis_activation_spread               33425 non-null  float64\n",
      " 12  z_PlacementSpread                       33425 non-null  float64\n",
      " 13  price_vs_placement_bid                  33425 non-null  float64\n",
      " 14  price_vs_placement_ask                  33425 non-null  float64\n",
      " 15  price_vs_activation_bid                 33425 non-null  float64\n",
      " 16  price_vs_activation_ask                 33425 non-null  float64\n",
      " 17  pre_placement_vs_received_time_diff     33425 non-null  float64\n",
      " 18  price_vs_pre_placement_book_join_price  33425 non-null  float64\n",
      "dtypes: float64(12), int64(3), object(4)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for test set and leave out the prediction column ('missed')\n",
    "X = test_df[['AGGRESSIVE','AWAY','JOINED','INSIDE','BUY','time_difference','z_USDEquivalentAmount','price_vs_placement_bid','pre_placement_vs_received_time_diff','price_vs_pre_placement_book_join_price','z_PlacementSpread']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a data frame with the same order of columns so I can use it to label the results\n",
    "df_columns = test_df[['AGGRESSIVE','AWAY','JOINED','INSIDE','BUY','time_difference','z_USDEquivalentAmount','price_vs_placement_bid','pre_placement_vs_received_time_diff','price_vs_pre_placement_book_join_price','z_PlacementSpread']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the predicted column ('missed') to the y variable\n",
    "y = test_df['MISSED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the dataset based on the training set scaling\n",
    "# need to load the saved scaler\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\random_forest_10.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction (tree Intepreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the tree interpreter\n",
    "prediction, bias, contribution = ti.predict(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created empty lists for the results/scores  to append to\n",
    "predictions = []\n",
    "AGGRESSIVE = []\n",
    "AWAY = []\n",
    "JOINED = []\n",
    "INSIDE = []\n",
    "time_difference = []\n",
    "z_USDEquivalentAmount = []\n",
    "price_vs_placement_bid = []\n",
    "pre_placement_vs_received_time_diff = []\n",
    "price_vs_pre_placement_book_join_price = []\n",
    "z_PlacementSpread = []\n",
    "BUY = []\n",
    "biased = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reshape(1,-1)\n",
    "# I created a for loop to run the test set through the tree interpreter and then append to the lists\n",
    "for predict in range(len(X_new)):\n",
    "    prediction, bias, contribution = ti.predict(clf, X_new[predict].reshape(1,-1))\n",
    "    predictions.append(prediction)\n",
    "    AGGRESSIVE.append(contribution[0][0])\n",
    "    AWAY.append(contribution[0][1])\n",
    "    JOINED.append(contribution[0][2])\n",
    "    BUY.append(contribution[0][3])\n",
    "    INSIDE.append(contribution[0][4])\n",
    "    time_difference.append(contribution[0][5])\n",
    "    z_USDEquivalentAmount.append(contribution[0][6])\n",
    "    price_vs_placement_bid.append(contribution[0][7])\n",
    "    pre_placement_vs_received_time_diff.append(contribution[0][8])\n",
    "    price_vs_pre_placement_book_join_price.append(contribution[0][9])\n",
    "    z_PlacementSpread.append(contribution[0][10])\n",
    "    biased.append(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created a data fram with the results\n",
    "tree_interpret_results = pd.DataFrame()\n",
    "tree_interpret_results['predictions']=predictions\n",
    "tree_interpret_results['AGGRESSIVE'] = AGGRESSIVE\n",
    "tree_interpret_results['AWAY'] = AWAY\n",
    "tree_interpret_results['JOINED']=JOINED\n",
    "tree_interpret_results['INSIDE']=INSIDE\n",
    "tree_interpret_results['BUY']=BUY\n",
    "tree_interpret_results['time_difference']=time_difference\n",
    "tree_interpret_results['z_USDEquivalentAmount']=z_USDEquivalentAmount\n",
    "tree_interpret_results['price_vs_placement_bid']=price_vs_placement_bid\n",
    "tree_interpret_results['pre_placement_vs_received_time_diff']=pre_placement_vs_received_time_diff\n",
    "tree_interpret_results['price_vs_pre_placement_book_join_price']=price_vs_pre_placement_book_join_price\n",
    "tree_interpret_results['z_PlacementSpread']=z_PlacementSpread\n",
    "tree_interpret_results['bias'] = biased\n",
    "tree_interpret_results.to_csv('tree_interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGGRESSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I print out the results to see what the output is\n",
    "print(\"Prediction\", prediction)\n",
    "print(\"Bias (trainset prior)\", bias)\n",
    "print (\"Feature contributions:\")\n",
    "#zipped = zip(contributions[0],df_columns.columns)\n",
    "#zipped = zip(df_columns.columns,contributions[0])\n",
    "for c, feature in zip(contributions,df_columns.columns):\n",
    "#for feature, c in sorted(zipped, key=lambda x: x[1]):    \n",
    "    print(feature, c)\n",
    "#sorted(zipped, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created a data frame of the columns and contributionand graphed a bar chart\n",
    "pred = list(zip(contributions[0],df_columns.columns))\n",
    "\n",
    "decom = pd.DataFrame(pred)\n",
    "\n",
    "decom['score'] = decom['score'].apply(lambda x: x[1])\n",
    "\n",
    "decom.columns = ['score','labels']\n",
    "\n",
    "px.bar(decom,x= 'score',y = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tree_interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = df[['AGGRESSIVE','AWAY','JOINED','INSIDE','BUY','time_difference','z_USDEquivalentAmount','price_vs_placement_bid','pre_placement_vs_received_time_diff','price_vs_pre_placement_book_join_price','z_PlacementSpread']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_transform.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform['AGGRESSIVE'] = df_transform['AGGRESSIVE'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['AWAY'] = df_transform['AWAY'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['JOINED'] = df_transform['JOINED'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['INSIDE'] = df_transform['INSIDE'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['BUY'] = df_transform['BUY'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['time_difference'] = df_transform['time_difference'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['z_USDEquivalentAmount'] = df_transform['z_USDEquivalentAmount'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['price_vs_placement_bid'] = df_transform['price_vs_placement_bid'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['price_vs_placement_bid'] = df_transform['price_vs_placement_bid'].apply(lambda x: splitter(x))\n",
    "\n",
    "df_transform['pre_placement_vs_received_time_diff'] = df_transform['pre_placement_vs_received_time_diff'].apply(lambda x: splitter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['price_vs_pre_placement_book_join_price'] = df_transform['price_vs_pre_placement_book_join_price'].apply(lambda x: splitter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['z_PlacementSpread'] = df_transform['z_PlacementSpread'].apply(lambda x: splitter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(x):\n",
    "    floated = []\n",
    "    x= x[1:-1]\n",
    "    x = x.split(' ')\n",
    "    for i in range(len(x)):\n",
    "        if len(x[i]) > 4:\n",
    "            floated.append(float(x[i]))\n",
    "    return floated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_splitter(x):\n",
    "    floated = []\n",
    "    x= x[2:-2]\n",
    "    x = x.split(' ')\n",
    "    for i in range(len(x)):\n",
    "        if len(x[i]) > 4:\n",
    "            floated.append(float(x[i]))\n",
    "    return floated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['predictions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df_transform['predictions'])):\n",
    "    if len(df_transform['predictions'][x]) < 3:\n",
    "        print(df_transform['predictions'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform['bias'] = df['bias'].apply(lambda x: bias_splitter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_transform['predictions'] = df['predictions'].apply(lambda x: bias_splitter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df_transform['predictions'])):\n",
    "    try:\n",
    "        if df_transform['predictions'][x][0]>df_transform['predictions'][x][1]:\n",
    "            winners.append(0)\n",
    "        else:\n",
    "            winners.append(1)\n",
    "    except:\n",
    "        winners.append(df_transform['predictions'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_win = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(winners)):\n",
    "    if winners[x] == []:\n",
    "        clean_win.append(None)\n",
    "    else:\n",
    "        clean_win.append(winners[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform['winner'] = clean_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = df_transform.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(x):\n",
    "    af[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.iloc.apply(lambda x:x=x[af['winner'][x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(x):\n",
    "    try:\n",
    "        if x[0]>x[1]==True:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        outliers.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.to_csv('interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.read_csv(r'tree_interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = af[af['winner']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled = af[af['winner']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "af[af['winner']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed = list(filled.columns)\n",
    "#filled['AWAY'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filled['AWAY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filled[listed[1]] = filled[listed[1]].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unfilled.apply(lambda x: x.pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in unfilled.columns:\n",
    "    unfilled[name] = unfilled[name].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unfilled.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform[df_transform['winner']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unfilled = unfilled.apply(lambda x: x*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled['predictions'] = unfilled['predictions'].apply(lambda x: x*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled['bias'] = unfilled['bias'].apply(lambda x: x*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled['winner'] = unfilled['winner'].apply(lambda x: x*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = pd.merge(unfilled,filled,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['winner'] = filtered['winner'].replace(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.to_csv('filtered_intepreted_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics = filtered[['AGGRESSIVE', 'AWAY', 'JOINED', 'INSIDE', 'BUY', 'time_difference',\n",
    "       'z_USDEquivalentAmount', 'price_vs_placement_bid',\n",
    "       'pre_placement_vs_received_time_diff',\n",
    "       'price_vs_pre_placement_book_join_price', 'z_PlacementSpread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered['bias'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered['AWAY'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(characteristics.abs().mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform['winner'] = df_transform['predictions'].apply(lambda x: winner(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floated = []\n",
    "x= x[1:-1]\n",
    "x = x.split(' ')\n",
    "for i in range(len(x)):\n",
    "    if len(x[i]) > 4:\n",
    "        floated.append(x[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af['AWAY'].filter((l,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= x[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' ' not in y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = x[1:-1]\n",
    "c = b.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' ' not in(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floated = []\n",
    "x= x[1:-1]\n",
    "x = x.split(' ')\n",
    "#floated.append(float(x[-2]))\n",
    "#floated.append(float(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splitter(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_vs_pre_placement_book_join_price'][0][1:-1].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
