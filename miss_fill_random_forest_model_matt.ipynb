{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddunn.CUREXCURRENCY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import plotly_express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn import metrics\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for transforming new datasets\n",
    "metrics = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\Denis_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed test set\n",
    "test_df = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\transformed_new_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for test set and leave out the prediction column ('missed')\n",
    "X = test_df[['AGGRESSIVE','AWAY','JOINED','INSIDE','BUY','time_difference','z_USDEquivalentAmount','price_vs_placement_bid','pre_placement_vs_received_time_diff','price_vs_pre_placement_book_join_price','z_PlacementSpread']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a data frame with the same order of columns so I can use it to label the results\n",
    "df_columns = test_df[['AGGRESSIVE','AWAY','JOINED','INSIDE','BUY','time_difference','z_USDEquivalentAmount','price_vs_placement_bid','pre_placement_vs_received_time_diff','price_vs_pre_placement_book_join_price','z_PlacementSpread']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the predicted column ('missed') to the y variable\n",
    "y = test_df['MISSED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the dataset based on the training set scaling\n",
    "# need to load the saved scaler\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\random_forest_10.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction (tree Intepreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the tree interpreter\n",
    "prediction, bias, contribution = ti.predict(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created empty lists for the results/scores  to append to\n",
    "predictions = []\n",
    "AGGRESSIVE = []\n",
    "AWAY = []\n",
    "JOINED = []\n",
    "INSIDE = []\n",
    "time_difference = []\n",
    "z_USDEquivalentAmount = []\n",
    "price_vs_placement_bid = []\n",
    "pre_placement_vs_received_time_diff = []\n",
    "price_vs_pre_placement_book_join_price = []\n",
    "z_PlacementSpread = []\n",
    "BUY = []\n",
    "biased = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reshape(1,-1)\n",
    "# I created a for loop to run the test set through the tree interpreter and then append to the lists\n",
    "for predict in range(len(X_new)):\n",
    "    prediction, bias, contribution = ti.predict(clf, X_new[predict].reshape(1,-1))\n",
    "    predictions.append(prediction)\n",
    "    AGGRESSIVE.append(contribution[0][0])\n",
    "    AWAY.append(contribution[0][1])\n",
    "    JOINED.append(contribution[0][2])\n",
    "    BUY.append(contribution[0][3])\n",
    "    INSIDE.append(contribution[0][4])\n",
    "    time_difference.append(contribution[0][5])\n",
    "    z_USDEquivalentAmount.append(contribution[0][6])\n",
    "    price_vs_placement_bid.append(contribution[0][7])\n",
    "    pre_placement_vs_received_time_diff.append(contribution[0][8])\n",
    "    price_vs_pre_placement_book_join_price.append(contribution[0][9])\n",
    "    z_PlacementSpread.append(contribution[0][10])\n",
    "    biased.append(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created a data fram with the results\n",
    "tree_interpret_results = pd.DataFrame()\n",
    "tree_interpret_results['predictions']=predictions\n",
    "tree_interpret_results['AGGRESSIVE'] = AGGRESSIVE\n",
    "tree_interpret_results['AWAY'] = AWAY\n",
    "tree_interpret_results['JOINED']=JOINED\n",
    "tree_interpret_results['INSIDE']=INSIDE\n",
    "tree_interpret_results['BUY']=BUY\n",
    "tree_interpret_results['time_difference']=time_difference\n",
    "tree_interpret_results['z_USDEquivalentAmount']=z_USDEquivalentAmount\n",
    "tree_interpret_results['price_vs_placement_bid']=price_vs_placement_bid\n",
    "tree_interpret_results['pre_placement_vs_received_time_diff']=pre_placement_vs_received_time_diff\n",
    "tree_interpret_results['price_vs_pre_placement_book_join_price']=price_vs_pre_placement_book_join_price\n",
    "tree_interpret_results['z_PlacementSpread']=z_PlacementSpread\n",
    "tree_interpret_results['bias'] = biased\n",
    "tree_interpret_results.to_csv('tree_interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I print out the results to see what the output is\n",
    "print(\"Prediction\", prediction)\n",
    "print(\"Bias (trainset prior)\", bias)\n",
    "print (\"Feature contributions:\")\n",
    "#zipped = zip(contributions[0],df_columns.columns)\n",
    "#zipped = zip(df_columns.columns,contributions[0])\n",
    "for c, feature in zip(contributions,df_columns.columns):\n",
    "#for feature, c in sorted(zipped, key=lambda x: x[1]):    \n",
    "    print(feature, c)\n",
    "#sorted(zipped, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i created a data frame of the columns and contributionand graphed a bar chart\n",
    "pred = list(zip(contributions[0],df_columns.columns))\n",
    "\n",
    "decom = pd.DataFrame(pred)\n",
    "\n",
    "decom['score'] = decom['score'].apply(lambda x: x[1])\n",
    "\n",
    "decom.columns = ['score','labels']\n",
    "\n",
    "px.bar(decom,x= 'score',y = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial output of tree interpreter\n",
    "#df = pd.read_csv('tree_interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#af.to_csv('interpreter_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaned into a dataframe\n",
    "results = pd.read_csv(r\"S:\\Data Analytics Group\\FillsAndMissesStudy\\Csv_From_SQL_Server\\interpreter_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
